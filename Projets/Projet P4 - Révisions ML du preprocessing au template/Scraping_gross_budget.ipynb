{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_h3GW7YI3SY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Dans le dataset initial (5000_movies.csv)**, il y a beaucoup de valeurs manquantes dans `gross` et dans `budget` donc imputation délicate mais comme on veut garder ces variables, on va alors supprimer les lignes. Avant cette suppression on peut essayer de scraper IMDB pour obtenir des informations supplémentaires. Pour cela, un petit notebook séparé dans le même dossier permet de récupérer les données supplémentaires éventuelles, de les ajouter dans les colonnes `gross` et `budget` du dataframe `data`. Comme l'éxecution est un peu longue, on va sauvegarder ce dataframe dans un nouveau csv pour ne pas avoir à le refaire à chaque fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5043 entries, 0 to 5042\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   color                   5024 non-null   object \n",
      " 1   director_name           4939 non-null   object \n",
      " 2   num_critic_for_reviews  4993 non-null   float64\n",
      " 3   duration                5028 non-null   float64\n",
      " 4   director_fb_likes       4939 non-null   float64\n",
      " 5   actor_3_fb_likes        5020 non-null   float64\n",
      " 6   actor_2_name            5030 non-null   object \n",
      " 7   actor_1_fb_likes        5036 non-null   float64\n",
      " 8   gross                   4159 non-null   float64\n",
      " 9   genres                  5043 non-null   object \n",
      " 10  actor_1_name            5036 non-null   object \n",
      " 11  movie_title             5043 non-null   object \n",
      " 12  num_voted_users         5043 non-null   int64  \n",
      " 13  cast_total_fb_likes     5043 non-null   int64  \n",
      " 14  actor_3_name            5020 non-null   object \n",
      " 15  facenumber_in_poster    5030 non-null   float64\n",
      " 16  plot_keywords           4890 non-null   object \n",
      " 17  movie_imdb_link         5043 non-null   object \n",
      " 18  num_user_for_reviews    5022 non-null   float64\n",
      " 19  language                5031 non-null   object \n",
      " 20  country                 5038 non-null   object \n",
      " 21  content_rating          4740 non-null   object \n",
      " 22  budget                  4551 non-null   float64\n",
      " 23  title_year              4935 non-null   float64\n",
      " 24  actor_2_fb_likes        5030 non-null   float64\n",
      " 25  imdb_score              5043 non-null   float64\n",
      " 26  aspect_ratio            4714 non-null   float64\n",
      " 27  movie_fb_likes          5043 non-null   int64  \n",
      "dtypes: float64(13), int64(3), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5000_movies.csv')\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color                      19\n",
       "director_name             104\n",
       "num_critic_for_reviews     50\n",
       "duration                   15\n",
       "director_fb_likes         104\n",
       "actor_3_fb_likes           23\n",
       "actor_2_name               13\n",
       "actor_1_fb_likes            7\n",
       "gross                     884\n",
       "genres                      0\n",
       "actor_1_name                7\n",
       "movie_title                 0\n",
       "num_voted_users             0\n",
       "cast_total_fb_likes         0\n",
       "actor_3_name               23\n",
       "facenumber_in_poster       13\n",
       "plot_keywords             153\n",
       "movie_imdb_link             0\n",
       "num_user_for_reviews       21\n",
       "language                   12\n",
       "country                     5\n",
       "content_rating            303\n",
       "budget                    492\n",
       "title_year                108\n",
       "actor_2_fb_likes           13\n",
       "imdb_score                  0\n",
       "aspect_ratio              329\n",
       "movie_fb_likes              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping des données 'gross' et 'budget'\n",
    "def scrap_gross_budget(row):\n",
    "    link = row['movie_imdb_link']\n",
    "    \n",
    "    # si une des valeurs est manquante on va tenter d'aller les chercher\n",
    "    if (np.isnan(row['gross'])) | (np.isnan(row['budget'])) :\n",
    "        try :\n",
    "            # on récupère la page web\n",
    "            page = urlopen(link).read()\n",
    "            soup = BeautifulSoup(page)\n",
    "\n",
    "            # on récupère dans la page le Domestic Gross\n",
    "            scrap_gross = soup.find('li', {'data-testid':'title-boxoffice-grossdomestic'}).find('span', {'class':\"ipc-metadata-list-item__list-content-item\"})\n",
    "            scrap_gross = float(''.join(c for c in scrap_gross.contents[0] if c.isdigit()))\n",
    "\n",
    "            # on récupère dans la page le Budget\n",
    "            scrap_budget = soup.find('li', {'data-testid':'title-boxoffice-budget'}).find('span', {'class':\"ipc-metadata-list-item__list-content-item\"})\n",
    "            scrap_budget = float(''.join(c for c in scrap_budget.contents[0] if c.isdigit()))\n",
    "                    \n",
    "        except AttributeError as err:\n",
    "            return row[['gross', 'budget']]\n",
    "    \n",
    "    if (np.isnan(row['gross'])) & (np.isnan(row['budget'])) :\n",
    "        return scrap_gross, scrap_budget\n",
    "    \n",
    "    elif (np.isnan(row['gross'])) :\n",
    "        return scrap_gross, row['budget']\n",
    "    \n",
    "    elif (np.isnan(row['budget'])) :\n",
    "        return row['gross'], scrap_budget\n",
    "    \n",
    "    else:\n",
    "        return row[['gross', 'budget']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5043/5043 [54:46<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "data[['gross', 'budget']] = data.progress_apply(scrap_gross_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrement du dataframe en csv\n",
    "data.to_csv('5000_movies_bis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
